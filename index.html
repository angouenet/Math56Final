<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>5e4f2d769ad0499f94d8bca9f363f4d5</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="imports-and-setup-of-data" class="cell markdown"
id="vDbAj9WADdz5">
<h1>Imports and Setup of Data</h1>
</section>
<div class="cell code" data-execution_count="2" id="tpQXKeb3L-ko">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">&quot;svg&quot;</span></span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:653}"
id="HK3H0s0DMVhv" data-outputId="93ede870-369c-4f4f-e2a1-cda040833d8d">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load our data from our github</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">#Use last 5 seasons of basketball statistics</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Note: This spreadsheet was created by us from multiple different sources</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> pd.read_excel(<span class="st">&quot;https://github.com/afick/NBAStatsAnalysis/blob/main/fullStats.xlsx?raw=true&quot;</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out empty columns</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> df1.loc[:, <span class="op">~</span>df1.columns.<span class="bu">str</span>.contains(<span class="st">&#39;^Unnamed&#39;</span>)]</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert values to float</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>df1.iloc[:,<span class="dv">2</span>:<span class="op">-</span><span class="dv">2</span>] <span class="op">=</span> df1.iloc[:,<span class="dv">2</span>:<span class="op">-</span><span class="dv">2</span>].astype(<span class="bu">float</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">&#39;MOV&#39;</span>] <span class="op">=</span> df1[<span class="st">&#39;MOV&#39;</span>].astype(<span class="bu">float</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert values to ints</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">&#39;G&#39;</span>] <span class="op">=</span> df1[<span class="st">&#39;G&#39;</span>].astype(<span class="bu">int</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">&#39;Year&#39;</span>] <span class="op">=</span> df1[<span class="st">&#39;Year&#39;</span>].astype(<span class="bu">int</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">&#39;Wins&#39;</span>] <span class="op">=</span> df1[<span class="st">&#39;Wins&#39;</span>].astype(<span class="bu">int</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>df1</span></code></pre></div>
<div class="output execute_result" data-execution_count="2">

  <div id="df-9c1d4062-0578-4943-ad73-f4f2fea6c681">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Team</th>
      <th>G</th>
      <th>MP</th>
      <th>FG</th>
      <th>FGA</th>
      <th>FG%</th>
      <th>3P</th>
      <th>3PA</th>
      <th>3P%</th>
      <th>2P</th>
      <th>...</th>
      <th>STL</th>
      <th>BLK</th>
      <th>TOV</th>
      <th>PF</th>
      <th>PTS</th>
      <th>Year</th>
      <th>TS%</th>
      <th>Wins</th>
      <th>Playoffs</th>
      <th>MOV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Atlanta Hawks*</td>
      <td>82</td>
      <td>19705.0</td>
      <td>3401.0</td>
      <td>7241.0</td>
      <td>0.470</td>
      <td>1056.0</td>
      <td>2821.0</td>
      <td>0.374</td>
      <td>2345.0</td>
      <td>...</td>
      <td>587.0</td>
      <td>348.0</td>
      <td>972.0</td>
      <td>1534.0</td>
      <td>9343.0</td>
      <td>2021</td>
      <td>0.581</td>
      <td>43</td>
      <td>Success</td>
      <td>1.56</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Boston Celtics*</td>
      <td>82</td>
      <td>19905.0</td>
      <td>3341.0</td>
      <td>7167.0</td>
      <td>0.466</td>
      <td>1085.0</td>
      <td>3044.0</td>
      <td>0.356</td>
      <td>2256.0</td>
      <td>...</td>
      <td>591.0</td>
      <td>478.0</td>
      <td>1118.0</td>
      <td>1521.0</td>
      <td>9164.0</td>
      <td>2021</td>
      <td>0.578</td>
      <td>51</td>
      <td>Finals</td>
      <td>7.28</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Brooklyn Nets*</td>
      <td>82</td>
      <td>19755.0</td>
      <td>3442.0</td>
      <td>7251.0</td>
      <td>0.475</td>
      <td>940.0</td>
      <td>2602.0</td>
      <td>0.361</td>
      <td>2502.0</td>
      <td>...</td>
      <td>582.0</td>
      <td>448.0</td>
      <td>1153.0</td>
      <td>1670.0</td>
      <td>9258.0</td>
      <td>2021</td>
      <td>0.576</td>
      <td>44</td>
      <td>Success</td>
      <td>0.78</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Charlotte Hornets</td>
      <td>82</td>
      <td>19880.0</td>
      <td>3508.0</td>
      <td>7497.0</td>
      <td>0.468</td>
      <td>1143.0</td>
      <td>3130.0</td>
      <td>0.365</td>
      <td>2365.0</td>
      <td>...</td>
      <td>707.0</td>
      <td>402.0</td>
      <td>1087.0</td>
      <td>1629.0</td>
      <td>9457.0</td>
      <td>2021</td>
      <td>0.572</td>
      <td>46</td>
      <td>Failure</td>
      <td>0.44</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Chicago Bulls*</td>
      <td>82</td>
      <td>19730.0</td>
      <td>3422.0</td>
      <td>7127.0</td>
      <td>0.480</td>
      <td>872.0</td>
      <td>2364.0</td>
      <td>0.369</td>
      <td>2550.0</td>
      <td>...</td>
      <td>585.0</td>
      <td>336.0</td>
      <td>1053.0</td>
      <td>1540.0</td>
      <td>9152.0</td>
      <td>2021</td>
      <td>0.579</td>
      <td>43</td>
      <td>Success</td>
      <td>-0.39</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>145</th>
      <td>Sacramento Kings</td>
      <td>82</td>
      <td>19755.0</td>
      <td>3179.0</td>
      <td>7063.0</td>
      <td>0.450</td>
      <td>738.0</td>
      <td>1967.0</td>
      <td>0.375</td>
      <td>2441.0</td>
      <td>...</td>
      <td>643.0</td>
      <td>340.0</td>
      <td>1125.0</td>
      <td>1639.0</td>
      <td>8104.0</td>
      <td>2017</td>
      <td>0.529</td>
      <td>27</td>
      <td>Failure</td>
      <td>-6.99</td>
    </tr>
    <tr>
      <th>146</th>
      <td>San Antonio Spurs*</td>
      <td>82</td>
      <td>19730.0</td>
      <td>3202.0</td>
      <td>6999.0</td>
      <td>0.457</td>
      <td>696.0</td>
      <td>1977.0</td>
      <td>0.352</td>
      <td>2506.0</td>
      <td>...</td>
      <td>628.0</td>
      <td>460.0</td>
      <td>1078.0</td>
      <td>1408.0</td>
      <td>8424.0</td>
      <td>2017</td>
      <td>0.543</td>
      <td>47</td>
      <td>Success</td>
      <td>2.89</td>
    </tr>
    <tr>
      <th>147</th>
      <td>Toronto Raptors*</td>
      <td>82</td>
      <td>19830.0</td>
      <td>3383.0</td>
      <td>7169.0</td>
      <td>0.472</td>
      <td>968.0</td>
      <td>2705.0</td>
      <td>0.358</td>
      <td>2415.0</td>
      <td>...</td>
      <td>626.0</td>
      <td>500.0</td>
      <td>1095.0</td>
      <td>1783.0</td>
      <td>9156.0</td>
      <td>2017</td>
      <td>0.575</td>
      <td>59</td>
      <td>Success</td>
      <td>7.78</td>
    </tr>
    <tr>
      <th>148</th>
      <td>Utah Jazz*</td>
      <td>82</td>
      <td>19755.0</td>
      <td>3139.0</td>
      <td>6797.0</td>
      <td>0.462</td>
      <td>887.0</td>
      <td>2425.0</td>
      <td>0.366</td>
      <td>2252.0</td>
      <td>...</td>
      <td>708.0</td>
      <td>420.0</td>
      <td>1205.0</td>
      <td>1608.0</td>
      <td>8540.0</td>
      <td>2017</td>
      <td>0.564</td>
      <td>48</td>
      <td>Success</td>
      <td>4.30</td>
    </tr>
    <tr>
      <th>149</th>
      <td>Washington Wizards*</td>
      <td>82</td>
      <td>19855.0</td>
      <td>3275.0</td>
      <td>7018.0</td>
      <td>0.467</td>
      <td>814.0</td>
      <td>2173.0</td>
      <td>0.375</td>
      <td>2461.0</td>
      <td>...</td>
      <td>645.0</td>
      <td>353.0</td>
      <td>1196.0</td>
      <td>1746.0</td>
      <td>8742.0</td>
      <td>2017</td>
      <td>0.560</td>
      <td>43</td>
      <td>Success</td>
      <td>0.59</td>
    </tr>
  </tbody>
</table>
<p>150 rows Ã— 29 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-9c1d4062-0578-4943-ad73-f4f2fea6c681')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-9c1d4062-0578-4943-ad73-f4f2fea6c681 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-9c1d4062-0578-4943-ad73-f4f2fea6c681');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="5-meB7JDEqB6" data-outputId="001cd5e0-e8e7-4357-9021-617637d80c17">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check out all the columns</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>df1.columns</span></code></pre></div>
<div class="output execute_result" data-execution_count="4">
<pre><code>Index([&#39;Team&#39;, &#39;G&#39;, &#39;MP&#39;, &#39;FG&#39;, &#39;FGA&#39;, &#39;FG%&#39;, &#39;3P&#39;, &#39;3PA&#39;, &#39;3P%&#39;, &#39;2P&#39;, &#39;2PA&#39;,
       &#39;2P%&#39;, &#39;FT&#39;, &#39;FTA&#39;, &#39;FT%&#39;, &#39;ORB&#39;, &#39;DRB&#39;, &#39;TRB&#39;, &#39;AST&#39;, &#39;STL&#39;, &#39;BLK&#39;,
       &#39;TOV&#39;, &#39;PF&#39;, &#39;PTS&#39;, &#39;Year&#39;, &#39;TS%&#39;, &#39;Wins&#39;, &#39;Playoffs&#39;, &#39;MOV&#39;],
      dtype=&#39;object&#39;)</code></pre>
</div>
</div>
<section id="building-new-features" class="cell markdown"
id="bUFB6042Dseq">
<h1>Building New Features</h1>
</section>
<div class="cell code" id="mPRhUJJ6UJD0">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select features relevant to our data analysis</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df_filtered <span class="op">=</span> df1[[<span class="st">&#39;Team&#39;</span>, <span class="st">&#39;FG%&#39;</span>, <span class="st">&#39;TS%&#39;</span>, <span class="st">&#39;3P%&#39;</span>, <span class="st">&#39;3PA&#39;</span>, <span class="st">&#39;FGA&#39;</span>, <span class="st">&#39;AST&#39;</span>, <span class="st">&#39;BLK&#39;</span>, <span class="st">&#39;TOV&#39;</span>, <span class="st">&#39;Wins&#39;</span>, <span class="st">&#39;G&#39;</span>, <span class="st">&#39;Playoffs&#39;</span>, <span class="st">&#39;MOV&#39;</span>, <span class="st">&#39;PTS&#39;</span>, <span class="st">&#39;Year&#39;</span>, <span class="st">&#39;FT%&#39;</span>, <span class="st">&#39;2P%&#39;</span>, <span class="st">&#39;TRB&#39;</span>]]</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create other useful predictors</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">&#39;</span><span class="sc">%3s</span><span class="st">&#39;</span>] <span class="op">=</span> df_filtered[<span class="st">&#39;3PA&#39;</span>]<span class="op">/</span>df_filtered[<span class="st">&#39;FGA&#39;</span>] <span class="co"># The % of a team&#39;s shots that are 3s</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">&#39;BLKpG&#39;</span>] <span class="op">=</span> df_filtered[<span class="st">&#39;BLK&#39;</span>]<span class="op">/</span>df_filtered[<span class="st">&#39;G&#39;</span>]</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">&#39;Win%&#39;</span>] <span class="op">=</span> df_filtered[<span class="st">&#39;Wins&#39;</span>]<span class="op">/</span>df_filtered[<span class="st">&#39;G&#39;</span>]</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">&#39;TOVpG&#39;</span>] <span class="op">=</span> df_filtered[<span class="st">&#39;TOV&#39;</span>]<span class="op">/</span>df_filtered[<span class="st">&#39;G&#39;</span>]</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">&#39;PTSpG&#39;</span>] <span class="op">=</span> df_filtered[<span class="st">&#39;PTS&#39;</span>]<span class="op">/</span>df_filtered[<span class="st">&#39;G&#39;</span>]</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">&#39;ASTpG&#39;</span>] <span class="op">=</span> df_filtered[<span class="st">&#39;AST&#39;</span>]<span class="op">/</span>df_filtered[<span class="st">&#39;G&#39;</span>]</span></code></pre></div>
</div>
<div class="cell code" id="GaBomgbt4xts">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check out some different winning percentages from the past 5 seasons (the extremes)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">&#39;Win%&#39;</span>].sort_values()</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="I_jSLFOpwlhk" data-outputId="764b36f6-049e-42fe-f5ee-7749561a2e2c">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The specific seasons of basketball that we are analyzing</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">&#39;Year&#39;</span>].unique()</span></code></pre></div>
<div class="output execute_result" data-execution_count="6">
<pre><code>array([2021, 2020, 2019, 2018, 2017])</code></pre>
</div>
</div>
<div class="cell markdown" id="jTX57aqiD2Cr">
<pre><code># This is formatted as code</code></pre>
<h1 id="volume-metric-stats">Volume Metric Stats</h1>
</div>
<div class="cell markdown" id="xcyr8mPT_hsX">

</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:736}"
id="4MaEaG9Yyk_V" data-outputId="3c1b9bfd-8d02-4017-d2ef-381be6df2e94">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Linear regression with only counting stats</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> df_filtered[[<span class="st">&quot;ASTpG&quot;</span>, <span class="st">&quot;BLKpG&quot;</span>, <span class="st">&#39;PTSpG&#39;</span>]]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data.to_numpy() <span class="co"># convert to numpy array</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(x) <span class="co"># add a column of all 1s</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_filtered[[<span class="st">&quot;Win%&quot;</span>]].to_numpy()</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y,X) <span class="co">#run OLS</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.fit()</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.summary())</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Graph residuals</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> results.resid</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>y_mean_pred <span class="op">=</span> y <span class="op">-</span> r</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">2</span>))</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,r,<span class="st">&quot;o&quot;</span>, alpha <span class="op">=</span> <span class="fl">0.25</span>)  <span class="co"># Plot the residuals</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,np.zeros(<span class="bu">len</span>(y)),<span class="st">&quot;-&quot;</span>) <span class="co"># Plot the reference line of 0</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;Win% prediction&quot;</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Residual&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.300
Model:                            OLS   Adj. R-squared:                  0.286
Method:                 Least Squares   F-statistic:                     20.85
Date:                Mon, 21 Nov 2022   Prob (F-statistic):           2.67e-11
Time:                        02:22:52   Log-Likelihood:                 104.87
No. Observations:                 150   AIC:                            -201.7
Df Residuals:                     146   BIC:                            -189.7
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         -1.4538      0.254     -5.731      0.000      -1.955      -0.952
x1            -0.0001      0.006     -0.022      0.983      -0.012       0.012
x2             0.0209      0.015      1.377      0.171      -0.009       0.051
x3             0.0168      0.003      6.128      0.000       0.011       0.022
==============================================================================
Omnibus:                        7.702   Durbin-Watson:                   1.744
Prob(Omnibus):                  0.021   Jarque-Bera (JB):                4.017
Skew:                          -0.170   Prob(JB):                        0.134
Kurtosis:                       2.274   Cond. No.                     2.89e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.89e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</code></pre>
</div>
<div class="output execute_result" data-execution_count="6">
<pre><code>Text(0, 0.5, &#39;Residual&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_6a94bd04c1aa4184ad4edddf210b7d1e/467f07dc8e0d9f56b1f3b1936f81e8720719129b.svg" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="cYEvftD3_tuk" data-outputId="131adde4-1765-494f-bc1d-26da877a4dd3">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine what is more significant (BLKpG vs PTSpG)</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>const, t, b, p <span class="op">=</span> results.params</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>signf_b <span class="op">=</span> b <span class="op">*</span> np.std(data.BLKpG)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>signf_p <span class="op">=</span> p <span class="op">*</span> np.std(data.PTSpG)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Significance of BLKSpG: </span><span class="sc">{</span>signf_b<span class="sc">}</span><span class="ch">\n</span><span class="ss">Significance of PTSpG: </span><span class="sc">{</span>signf_p<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Significance of BLKSpG: 0.014563498028598796
Significance of PTSpG: 0.07292497706375321
</code></pre>
</div>
</div>
<section id="efficiency-metric-model" class="cell markdown"
id="tfdKX43nEU66">
<h1>Efficiency Metric Model</h1>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:726}"
id="U0Hl_Tk_5POR" data-outputId="0290ca82-5bd8-4548-eb73-5917f95f0f7b">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Linear regression with 3 features (all the different shooting percentage statistics)</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> df_filtered[[<span class="st">&#39;FT%&#39;</span>, <span class="st">&#39;2P%&#39;</span>,<span class="st">&#39;3P%&#39;</span>]]</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data.to_numpy() <span class="co"># convert to numpy array</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(x) <span class="co"># add a column of all 1s</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_filtered[[<span class="st">&quot;Win%&quot;</span>]].to_numpy()</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y,X) <span class="co">#run OLS</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.fit()</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.summary())</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Graph residuals</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> results.resid</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>y_mean_pred <span class="op">=</span> y <span class="op">-</span> r</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">2</span>))</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,r,<span class="st">&quot;o&quot;</span>, alpha <span class="op">=</span> <span class="fl">0.25</span>)  <span class="co"># Plot the residuals</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,np.zeros(<span class="bu">len</span>(y)),<span class="st">&quot;-&quot;</span>) <span class="co"># Plot the reference line of 0</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;Win% prediction&quot;</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Residual&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.522
Model:                            OLS   Adj. R-squared:                  0.512
Method:                 Least Squares   F-statistic:                     53.18
Date:                Sat, 19 Nov 2022   Prob (F-statistic):           2.73e-23
Time:                        03:34:55   Log-Likelihood:                 133.51
No. Observations:                 150   AIC:                            -259.0
Df Residuals:                     146   BIC:                            -247.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         -2.8111      0.293     -9.602      0.000      -3.390      -2.233
x1             0.0979      0.321      0.305      0.761      -0.536       0.732
x2             3.1285      0.396      7.902      0.000       2.346       3.911
x3             4.4473      0.602      7.390      0.000       3.258       5.637
==============================================================================
Omnibus:                        2.385   Durbin-Watson:                   1.867
Prob(Omnibus):                  0.304   Jarque-Bera (JB):                1.891
Skew:                           0.122   Prob(JB):                        0.388
Kurtosis:                       2.507   Cond. No.                         108.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</code></pre>
</div>
<div class="output execute_result" data-execution_count="31">
<pre><code>Text(0, 0.5, &#39;Residual&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6a94bd04c1aa4184ad4edddf210b7d1e/ddc122928baa1cc44ce076a064ba76e54a59a097.svg" /></p>
</div>
</div>
<section id="playmaker-model" class="cell markdown" id="hmKPxLRTEBoN">
<h1>Playmaker Model</h1>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:726}"
id="trzCE3Vi2W-f" data-outputId="b10f354b-0b46-4993-f3ef-2761a1dc20d1">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Linear regression with 3 different features (low R^2 in this case)</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> df_filtered[[<span class="st">&#39;TOVpG&#39;</span>,<span class="st">&#39;</span><span class="sc">%3s</span><span class="st">&#39;</span>, <span class="st">&#39;ASTpG&#39;</span>]]</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data.to_numpy() <span class="co"># convert to numpy array</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(x) <span class="co"># add a column of all 1s</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_filtered[[<span class="st">&quot;Win%&quot;</span>]].to_numpy()</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y,X) <span class="co">#run OLS</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.fit()</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.summary())</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Graph residuals</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> results.resid</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>y_mean_pred <span class="op">=</span> y <span class="op">-</span> r</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">2</span>))</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,r,<span class="st">&quot;o&quot;</span>, alpha <span class="op">=</span> <span class="fl">0.25</span>)  <span class="co"># Plot the residuals</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,np.zeros(<span class="bu">len</span>(y)),<span class="st">&quot;-&quot;</span>) <span class="co"># Plot the reference line of 0</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;Win% prediction&quot;</span>)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Residual&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.198
Model:                            OLS   Adj. R-squared:                  0.182
Method:                 Least Squares   F-statistic:                     12.04
Date:                Sat, 19 Nov 2022   Prob (F-statistic):           4.37e-07
Time:                        20:06:55   Log-Likelihood:                 94.702
No. Observations:                 150   AIC:                            -181.4
Df Residuals:                     146   BIC:                            -169.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.3493      0.193      1.810      0.072      -0.032       0.731
x1            -0.0438      0.010     -4.314      0.000      -0.064      -0.024
x2             0.4608      0.219      2.100      0.037       0.027       0.894
x3             0.0244      0.006      4.354      0.000       0.013       0.036
==============================================================================
Omnibus:                        9.740   Durbin-Watson:                   1.997
Prob(Omnibus):                  0.008   Jarque-Bera (JB):                4.001
Skew:                          -0.012   Prob(JB):                        0.135
Kurtosis:                       2.200   Cond. No.                         639.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</code></pre>
</div>
<div class="output execute_result" data-execution_count="9">
<pre><code>Text(0, 0.5, &#39;Residual&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6a94bd04c1aa4184ad4edddf210b7d1e/2fa88c749441192ba0f605478a32a9428e1a4907.svg" /></p>
</div>
</div>
<section id="categorical-variable-model" class="cell markdown"
id="4OaKfi8IEdKy">
<h1>Categorical Variable Model</h1>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:739}"
id="xn3avEAx9H8N" data-outputId="b6931d08-da7b-4863-cfb4-e7126f908928">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Linear regression with a categorical variable (have y be MOV)</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> df_filtered[[<span class="st">&#39;ASTpG&#39;</span>,<span class="st">&#39;Playoffs&#39;</span>]]</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data[<span class="st">&#39;Playoffs&#39;</span>].unique()) <span class="co">#See below all the categorical values possible</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>data_x_new <span class="op">=</span> pd.get_dummies(data,drop_first <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">#default will be failure (meaning no playoffs), then first predictor is making it to the</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co">#conference finals, and second is just making the playoffs (not all the way to the conference finals)</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data_x_new.to_numpy() <span class="co"># convert to numpy array</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(x) <span class="co"># add a column of all 1s</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_filtered[[<span class="st">&quot;MOV&quot;</span>]].to_numpy()</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y,X) <span class="co">#run OLS</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.fit()</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.summary())</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="co">#Graph residuals</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> results.resid</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>y_mean_pred <span class="op">=</span> y <span class="op">-</span> r</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">2</span>))</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,r,<span class="st">&quot;o&quot;</span>, alpha <span class="op">=</span> <span class="fl">0.25</span>)  <span class="co"># Plot the residuals</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,np.zeros(<span class="bu">len</span>(y)),<span class="st">&quot;-&quot;</span>) <span class="co"># Plot the reference line of 0</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;Plus Minus&quot;</span>) <span class="co">#Plus-minus is other way to describe MOV (Points for - Points against)</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Residual&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[&#39;Success&#39; &#39;Finals&#39; &#39;Failure&#39;]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.649
Model:                            OLS   Adj. R-squared:                  0.642
Method:                 Least Squares   F-statistic:                     90.00
Date:                Sat, 19 Nov 2022   Prob (F-statistic):           5.00e-33
Time:                        21:44:17   Log-Likelihood:                -367.17
No. Observations:                 150   AIC:                             742.3
Df Residuals:                     146   BIC:                             754.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const        -16.7677      2.971     -5.644      0.000     -22.640     -10.896
x1             0.5363      0.122      4.386      0.000       0.295       0.778
x2             8.3974      0.729     11.523      0.000       6.957       9.838
x3             6.5301      0.500     13.065      0.000       5.542       7.518
==============================================================================
Omnibus:                        3.275   Durbin-Watson:                   2.217
Prob(Omnibus):                  0.194   Jarque-Bera (JB):                2.404
Skew:                           0.151   Prob(JB):                        0.301
Kurtosis:                       2.459   Cond. No.                         314.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</code></pre>
</div>
<div class="output execute_result" data-execution_count="7">
<pre><code>Text(0, 0.5, &#39;Residual&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6a94bd04c1aa4184ad4edddf210b7d1e/dbce9323a5c3f8052ce8db3dfc6f3f795745946c.svg" /></p>
</div>
</div>
<section id="autoregressive-model" class="cell markdown"
id="98QEmKhdEiX0">
<h1>Autoregressive Model</h1>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:971}"
id="Dclrk9PfRaIR" data-outputId="2bc46c99-c32c-4d25-f6bf-becf67fb6492">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Autoregression of Wins year over year</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> df_filtered[[<span class="st">&#39;Year&#39;</span>, <span class="st">&#39;Win%&#39;</span>]]</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>minyear <span class="op">=</span> <span class="bu">min</span>(data.Year)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>maxyear <span class="op">=</span> <span class="bu">max</span>(data.Year)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Run linear regression</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[data.Year<span class="op">&lt;</span>maxyear]</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x[<span class="st">&#39;Win%&#39;</span>].to_numpy()</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[data.Year<span class="op">&gt;</span>minyear]</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y[<span class="st">&#39;Win%&#39;</span>].to_numpy()</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(x) <span class="co"># add a column of all 1s</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y,X) <span class="co">#run OLS</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.fit()</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.summary())</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>bhat, ahat <span class="op">=</span> results.params <span class="co">#Grab values</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>sigma_eps_hat <span class="op">=</span> np.sqrt(results.mse_resid)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Graph it</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Graph generated points from the line of best fit that include error</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">3</span>))</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>new_y <span class="op">=</span> np.zeros(<span class="bu">len</span>(x))</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(new_y)):</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>  new_y[i] <span class="op">=</span> ahat<span class="op">*</span>x[i] <span class="op">+</span> bhat <span class="op">+</span> np.random.normal(<span class="dv">0</span>, sigma_eps_hat)</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>ax.plot(x,new_y,<span class="st">&quot;o&quot;</span>, label<span class="op">=</span><span class="st">&quot;Predicted Win %&quot;</span>, alpha <span class="op">=</span> <span class="fl">0.75</span>)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>ax.plot(x,ahat<span class="op">*</span>x <span class="op">+</span> bhat, <span class="st">&#39;-&#39;</span>, label<span class="op">=</span><span class="st">&quot;Model Trendline&quot;</span>) <span class="co"># graph line of best fit</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>ax.plot(x,y,<span class="st">&quot;ko&quot;</span>,  label<span class="op">=</span><span class="st">&quot;Actual Win%&quot;</span>)</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;Winning Percentage Year 1&quot;</span>)</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Winning Percentage Year 2&quot;</span>)</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a><span class="co">#Graph residuals</span></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> results.resid</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>y_mean_pred <span class="op">=</span> y <span class="op">-</span> r</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">2</span>))</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,r,<span class="st">&quot;o&quot;</span>, alpha <span class="op">=</span> <span class="fl">0.25</span>)  <span class="co"># Plot the residuals</span></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,np.zeros(<span class="bu">len</span>(y)),<span class="st">&quot;-&quot;</span>) <span class="co"># Plot the reference line of 0</span></span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;Win%&quot;</span>)</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Residual&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.276
Model:                            OLS   Adj. R-squared:                  0.270
Method:                 Least Squares   F-statistic:                     45.02
Date:                Mon, 21 Nov 2022   Prob (F-statistic):           7.14e-10
Time:                        02:35:24   Log-Likelihood:                 82.491
No. Observations:                 120   AIC:                            -161.0
Df Residuals:                     118   BIC:                            -155.4
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.2402      0.040      5.984      0.000       0.161       0.320
x1             0.5185      0.077      6.710      0.000       0.365       0.671
==============================================================================
Omnibus:                        5.341   Durbin-Watson:                   1.995
Prob(Omnibus):                  0.069   Jarque-Bera (JB):                5.038
Skew:                          -0.499   Prob(JB):                       0.0805
Kurtosis:                       3.109   Cond. No.                         8.64
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</code></pre>
</div>
<div class="output execute_result" data-execution_count="12">
<pre><code>Text(0, 0.5, &#39;Residual&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6a94bd04c1aa4184ad4edddf210b7d1e/c7b78579d10f949605251fc53de3959adcc00623.svg" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_6a94bd04c1aa4184ad4edddf210b7d1e/d31f416bcb6e2908de9784fac59b25d9abf21222.svg" /></p>
</div>
</div>
<section id="extra-ts-feature-model" class="cell markdown"
id="hAa2_iXwEnoh">
<h1>Extra TS% Feature Model</h1>
</section>
<div class="cell code" id="P8U3sfBmndqr">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Adding possible features (see if it increases R^2)</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> df_filtered[[<span class="st">&#39;TS%&#39;</span>, <span class="st">&#39;Win%&#39;</span>]]</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;TS%2&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;TS%&#39;</span>]<span class="op">**</span><span class="dv">2</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;TS%3&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;TS%&#39;</span>]<span class="op">**</span><span class="dv">3</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;TS%4&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;TS%&#39;</span>]<span class="op">**</span><span class="dv">4</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;TS%5&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;TS%&#39;</span>]<span class="op">**</span><span class="dv">5</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;TS%6&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;TS%&#39;</span>]<span class="op">**</span><span class="dv">6</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;TS%7&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;TS%&#39;</span>]<span class="op">**</span><span class="dv">7</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;TS%8&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;TS%&#39;</span>]<span class="op">**</span><span class="dv">8</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;TS%9&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;TS%&#39;</span>]<span class="op">**</span><span class="dv">9</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;TS%10&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;TS%&#39;</span>]<span class="op">**</span><span class="dv">10</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[[<span class="st">&#39;Win%&#39;</span>]].to_numpy()</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co">#don&#39;t use any features for comparison</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[[<span class="st">&#39;TS%&#39;</span>]].to_numpy()</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(x) <span class="co"># add a column of all 1s</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y,X) <span class="co">#run OLS</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.fit()</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.summary())</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co">#Use 9 extra features (R^2 only minimally increases though)</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[[<span class="st">&#39;TS%&#39;</span>, <span class="st">&#39;TS%2&#39;</span>, <span class="st">&#39;TS%3&#39;</span>, <span class="st">&#39;TS%4&#39;</span>, <span class="st">&#39;TS%5&#39;</span>, <span class="st">&#39;TS%6&#39;</span>, <span class="st">&#39;TS%7&#39;</span>, <span class="st">&#39;TS%8&#39;</span>, <span class="st">&#39;TS%9&#39;</span>]].to_numpy()</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(x) <span class="co"># add a column of all 1s</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y,X) <span class="co">#run OLS</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.fit()</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.summary())</span></code></pre></div>
</div>
<section id="centered-vs-uncentered-r2" class="cell markdown"
id="tmAIAjAbEv6O">
<h1>Centered vs Uncentered <span
class="math inline"><em>R</em><sup>2</sup></span></h1>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="wovXYowmYr-o" data-outputId="dcf8acd3-1fa9-4750-ade0-f187062ee491">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Interesting observation (huge difference in R^2 when there is no constant)</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="co">## This uncovers the difference between centered vs uncentered R^2.</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co">## We didn&#39;t learn about this in class, but we can see that this uncentered R^2 is likely deceiving (residuals are not normal)</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co">## Point this out in our paper, but not really make any conclusions</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Linear regression with 1 features (with no constant)</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> df_filtered[[<span class="st">&#39;TS%&#39;</span>]]</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data.to_numpy() <span class="co"># convert to numpy array</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_filtered[[<span class="st">&quot;Win%&quot;</span>]].to_numpy()</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y,X) <span class="co">#run OLS</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.fit()</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.summary())</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot the data</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">3</span>))</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>ax.plot(X,y,<span class="st">&quot;o&quot;</span>,alpha<span class="op">=</span><span class="fl">0.4</span>) <span class="co">#</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a><span class="co">#Graph the line of best fit</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>a_fit <span class="op">=</span> results.params</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>ax.plot(X,X<span class="op">*</span>a_fit,<span class="st">&quot;-&quot;</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;TS%&quot;</span>)</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Win%&quot;</span>)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a><span class="co">#Graph residuals (clearly fails the normality criterion)</span></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> results.resid</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>y_mean_pred <span class="op">=</span> y <span class="op">-</span> r</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">2</span>))</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,r,<span class="st">&quot;o&quot;</span>, alpha <span class="op">=</span> <span class="fl">0.25</span>)  <span class="co"># Plot the residuals</span></span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,np.zeros(<span class="bu">len</span>(y)),<span class="st">&quot;-&quot;</span>) <span class="co"># Plot the reference line of 0</span></span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;Win prediction (w/out constant)&quot;</span>)</span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Residual&quot;</span>)</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a><span class="co">#Linear regression with same 1 features (with constant)</span></span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> df_filtered[[<span class="st">&#39;TS%&#39;</span>]]</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data.to_numpy() <span class="co"># convert to numpy array</span></span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(x) <span class="co"># add a column of all 1s</span></span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_filtered[[<span class="st">&quot;Win%&quot;</span>]].to_numpy()</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y,X) <span class="co">#run OLS</span></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.fit()</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.summary())</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot the data</span></span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">3</span>))</span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>ax.plot(x,y,<span class="st">&quot;o&quot;</span>,alpha<span class="op">=</span><span class="fl">0.4</span>) <span class="co">#</span></span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a><span class="co">#Graph the line of best fit</span></span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>b_fit,a_fit <span class="op">=</span> results.params</span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>ax.plot(x,x<span class="op">*</span>a_fit <span class="op">+</span> b_fit,<span class="st">&quot;-&quot;</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;TS%&quot;</span>)</span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Win%&quot;</span>)</span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a><span class="co">#Graph residuals</span></span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> results.resid</span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a>y_mean_pred <span class="op">=</span> y <span class="op">-</span> r</span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">2</span>))</span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,r,<span class="st">&quot;o&quot;</span>, alpha <span class="op">=</span> <span class="fl">0.25</span>)  <span class="co"># Plot the residuals</span></span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a>ax.plot(y_mean_pred,np.zeros(<span class="bu">len</span>(y)),<span class="st">&quot;-&quot;</span>) <span class="co"># Plot the reference line of 0</span></span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;Win prediction (w/ constant)&quot;</span>)</span>
<span id="cb28-59"><a href="#cb28-59" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Residual&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>                                 OLS Regression Results                                
=======================================================================================
Dep. Variable:                      y   R-squared (uncentered):                   0.934
Model:                            OLS   Adj. R-squared (uncentered):              0.933
Method:                 Least Squares   F-statistic:                              2105.
Date:                Mon, 21 Nov 2022   Prob (F-statistic):                    8.69e-90
Time:                        02:37:35   Log-Likelihood:                          89.190
No. Observations:                 150   AIC:                                     -176.4
Df Residuals:                     149   BIC:                                     -173.4
Df Model:                           1                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.8900      0.019     45.878      0.000       0.852       0.928
==============================================================================
Omnibus:                       19.316   Durbin-Watson:                   1.989
Prob(Omnibus):                  0.000   Jarque-Bera (JB):                6.483
Skew:                          -0.194   Prob(JB):                       0.0391
Kurtosis:                       2.058   Cond. No.                         1.00
==============================================================================

Notes:
[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.
[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.492
Model:                            OLS   Adj. R-squared:                  0.489
Method:                 Least Squares   F-statistic:                     143.4
Date:                Mon, 21 Nov 2022   Prob (F-statistic):           1.57e-23
Time:                        02:37:36   Log-Likelihood:                 128.94
No. Observations:                 150   AIC:                            -253.9
Df Residuals:                     148   BIC:                            -247.9
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         -2.8209      0.277    -10.170      0.000      -3.369      -2.273
x1             5.8904      0.492     11.974      0.000       4.918       6.862
==============================================================================
Omnibus:                        1.947   Durbin-Watson:                   1.909
Prob(Omnibus):                  0.378   Jarque-Bera (JB):                1.735
Skew:                           0.147   Prob(JB):                        0.420
Kurtosis:                       2.564   Cond. No.                         77.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</code></pre>
</div>
<div class="output execute_result" data-execution_count="15">
<pre><code>Text(0, 0.5, &#39;Residual&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6a94bd04c1aa4184ad4edddf210b7d1e/c12b8a2f6f75acd0864fd2b133c7be3f1fc15cd3.svg" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_6a94bd04c1aa4184ad4edddf210b7d1e/1c2669040c6324770eae04b4b2fa2ea2e5128cc3.svg" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_6a94bd04c1aa4184ad4edddf210b7d1e/303aace56f0a151b17756589b2c135478dac5e42.svg" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_6a94bd04c1aa4184ad4edddf210b7d1e/6599112b98a0ab6f7a553df3d5a3c7286395a48b.svg" /></p>
</div>
</div>
</body>
</html>
